_target_: dos.trainer.Trainer # Class Name

train_dataset:
  _target_: dos.datasets.ImageDataset       # Class Name
  root_dir: /scratch/shared/beegfs/oishideb/cow  # sample 1
  # root_dir: /work/oishideb/cow_sample_2  # sample 2
  # root_dir: /work/oishideb/cow_dataset/cow_dataset # 9 images
  # root_dir: /scratch/shared/beegfs/tomj/projects/articulator/datasets/synth_animals/cow-rd-articulator-v1.0  # Corrupted dataset
  attributes:
    - name: image
      suffix: _rgb.png
    - name: mask
      suffix: _mask.png
    - name: background
      suffix: _background.png
    - name: camera_matrix
      suffix: _camera.txt

model:
  _target_: dos.models.articulator.Articulator 
  bones_predictor:
    _target_: dos.components.skinning.bones_estimation.BonesEstimator
    num_body_bones: 8
    num_leg_bones: 3
    body_bones_type: z_minmax_y+
    temperature: 0.05

  path_to_save_images: /work/oishideb/dos_output_files/cow/all_iteration_Train/batch_size_0/DOS-1330-GS_20_Inf50
  num_pose: 25
  num_sample_bone_line: 2
  mode_kps_selection: "kps_fr_sample_on_bone_line" # Options are "kps_fr_sample_on_bone_line" OR "kps_fr_sample_farthest_points"
  shape_template_path: /scratch/shared/beegfs/tomj/projects/articulator/data/synth_animals/shape_templates/cow_female-rd/Cow-OBJ-v01/Cow_Highpoly.obj
  enable_texture_predictor: False
  view_option: "multi_view_azimu" # Options are "multi_view_azimu"; "multi_view_rand"; "single_view"

  articulation_predictor:
    _target_: dos.predictors.articulation_predictor.ArticulationPredictor  # Class Name
    size_dataset: 49
    num_bones: 20
    
  renderer:   # variable Name
    _target_: dos.modules.renderer.Renderer # Class Name
    cam_pos_z_offset: 0.0
    fov: 28.84 # blender 70 mm focal length, 36 mm sensor width

  diffusion_Text_to_Target_Img:  # variable Name
    _target_: dos.components.diffusion_model_text_to_image.diffusion_sds.DiffusionForTargetImg # Class Name
    cache_dir: /work/oishideb/cache/huggingface_hub
    output_dir: /work/oishideb/dos_output_files/cow/all_iteration_Train/batch_size_0/DOS-1330-GS_20_Inf50/sd_sds_output/
    init_image_path: /users/oishideb/laam/dos/examples/data/cow.png
    vis_name: cow-sds_latent-l2_image-600-lr1e-1.jpg
    prompts: 'A DSLR photo of a back-view full-size cow running very fast. The photo should have a grey background.' # DOS-1330  opti multi_view_azimu, GS20, Num_Infe50
    negative_prompts: 'cartoon, dead, shadow, reflection'     # the string shouldn't be in a square brackets ['']
    mode: sds_latent-l2_image # sds_image #
    lr: 0.1  # For DeepFloyd
    lr_l2: 1e4  # For SD+SDS
    seed: 2
    num_inference_steps: 50
    guidance_scale: 20
    select_deep_floyd: False

renderer:   # variable Name
  _target_: dos.modules.renderer.Renderer # Class Name
  cam_pos_z_offset: 0.0
  fov: 28.84

path_to_save_img_per_iteration: /work/oishideb/dos_output_files/cow/all_iteration_Train/batch_size_0/
checkpoint_root_dir: /work/oishideb/articulation_cow_chkpts
experiment_name: articulator-dev-0.1
save_each_iteration: False
evaluate_the_model: False

device: cuda:0

# resume: True

learning_rate: 0.1  # tried with 0.01, 0.5, 0.9, 1;   # 1e-4

# for debugging
num_iterations: 8
num_vis_iterations: 1
num_eval_iterations: 10
save_checkpoint_freq: 50
num_workers: 0
batch_size: 1